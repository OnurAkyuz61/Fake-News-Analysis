{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ Sahte Haber Analizi - GeliÅŸmiÅŸ Analizler ve Modelleme\n",
    "\n",
    "Bu notebook'ta geliÅŸmiÅŸ makine Ã¶ÄŸrenmesi modelleri ve deep learning yaklaÅŸÄ±mlarÄ± kullanacaÄŸÄ±z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "print(\"ğŸ¤– GeliÅŸmiÅŸ ML kÃ¼tÃ¼phaneleri hazÄ±r!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri hazÄ±rlama\n",
    "fake_news = pd.read_csv('../data/Fake.csv')\n",
    "real_news = pd.read_csv('../data/True.csv')\n",
    "\n",
    "fake_news['label'] = 0\n",
    "real_news['label'] = 1\n",
    "\n",
    "df = pd.concat([fake_news, real_news], ignore_index=True)\n",
    "df = df.dropna(subset=['title', 'text'])\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Metin birleÅŸtirme\n",
    "df['combined_text'] = df['title'] + ' ' + df['text']\n",
    "\n",
    "print(f\"ğŸ“Š GeliÅŸmiÅŸ analiz iÃ§in veri: {len(df):,} haber\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri setini bÃ¶l\n",
    "X = df['combined_text']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"ğŸ”„ EÄŸitim seti: {len(X_train):,}\")\n",
    "print(f\"ğŸ”„ Test seti: {len(X_test):,}\")\n",
    "\n",
    "# TF-IDF VektÃ¶rizasyon\n",
    "tfidf = TfidfVectorizer(max_features=15000, stop_words='english', \n",
    "                       lowercase=True, ngram_range=(1, 3), min_df=2, max_df=0.95)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(f\"âœ… TF-IDF: {X_train_tfidf.shape[1]} Ã¶zellik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GeliÅŸmiÅŸ modeller\n",
    "advanced_models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000, C=1.0),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=200, random_state=42, max_depth=20),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42, n_estimators=200, max_depth=6),\n",
    "    'LightGBM': LGBMClassifier(random_state=42, n_estimators=200, max_depth=6, verbose=-1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42, n_estimators=100),\n",
    "    'SVM': SVC(probability=True, random_state=42, C=1.0, kernel='rbf')\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(\"ğŸš€ GeliÅŸmiÅŸ modeller eÄŸitiliyor...\")\n",
    "\n",
    "for name, model in advanced_models.items():\n",
    "    print(f\"\\nğŸ”„ {name} eÄŸitiliyor...\")\n",
    "    \n",
    "    # EÄŸitim\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Tahmin\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    y_pred_proba = model.predict_proba(X_test_tfidf)[:, 1]\n",
    "    \n",
    "    # Cross validation\n",
    "    cv_scores = cross_val_score(model, X_train_tfidf, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # SonuÃ§larÄ± kaydet\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'predictions': y_pred,\n",
    "        'probabilities': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ… {name}:\")\n",
    "    print(f\"   DoÄŸruluk: {accuracy:.4f}\")\n",
    "    print(f\"   CV Ortalama: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})\")\n",
    "\n",
    "print(\"\\nğŸ¯ TÃ¼m geliÅŸmiÅŸ modeller eÄŸitildi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performans gÃ¶rselleÅŸtirmeleri\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. DoÄŸruluk karÅŸÄ±laÅŸtÄ±rmasÄ±\n",
    "model_names = list(results.keys())\n",
    "accuracies = [results[name]['accuracy'] for name in model_names]\n",
    "cv_means = [results[name]['cv_mean'] for name in model_names]\n",
    "\n",
    "x_pos = np.arange(len(model_names))\n",
    "bars1 = axes[0,0].bar(x_pos - 0.2, accuracies, 0.4, label='Test DoÄŸruluÄŸu', color='#ff6b6b')\n",
    "bars2 = axes[0,0].bar(x_pos + 0.2, cv_means, 0.4, label='CV DoÄŸruluÄŸu', color='#4ecdc4')\n",
    "\n",
    "axes[0,0].set_title('ğŸ¯ Model Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±', fontweight='bold')\n",
    "axes[0,0].set_ylabel('DoÄŸruluk OranÄ±')\n",
    "axes[0,0].set_xticks(x_pos)\n",
    "axes[0,0].set_xticklabels(model_names, rotation=45, ha='right')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# DeÄŸerleri bar Ã¼zerine yaz\n",
    "for bar, acc in zip(bars1, accuracies):\n",
    "    axes[0,0].text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.005,\n",
    "                  f'{acc:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# 2. En iyi modelin confusion matrix\n",
    "best_model_name = max(results.keys(), key=lambda k: results[k]['accuracy'])\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "\n",
    "cm = confusion_matrix(y_test, best_predictions)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0,1],\n",
    "           xticklabels=['Sahte', 'GerÃ§ek'], yticklabels=['Sahte', 'GerÃ§ek'])\n",
    "axes[0,1].set_title(f'ğŸ”¥ {best_model_name} - Confusion Matrix', fontweight='bold')\n",
    "axes[0,1].set_xlabel('Tahmin Edilen')\n",
    "axes[0,1].set_ylabel('GerÃ§ek')\n",
    "\n",
    "# 3. ROC eÄŸrileri\n",
    "colors = ['#ff6b6b', '#4ecdc4', '#45b7d1', '#96ceb4', '#feca57', '#ff9ff3']\n",
    "for i, name in enumerate(model_names):\n",
    "    fpr, tpr, _ = roc_curve(y_test, results[name]['probabilities'])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    axes[0,2].plot(fpr, tpr, color=colors[i % len(colors)], \n",
    "                  label=f'{name} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "axes[0,2].plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "axes[0,2].set_title('ğŸ“ˆ ROC EÄŸrileri KarÅŸÄ±laÅŸtÄ±rmasÄ±', fontweight='bold')\n",
    "axes[0,2].set_xlabel('False Positive Rate')\n",
    "axes[0,2].set_ylabel('True Positive Rate')\n",
    "axes[0,2].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axes[0,2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Precision-Recall eÄŸrileri\n",
    "for i, name in enumerate(model_names):\n",
    "    precision, recall, _ = precision_recall_curve(y_test, results[name]['probabilities'])\n",
    "    axes[1,0].plot(recall, precision, color=colors[i % len(colors)], label=name)\n",
    "\n",
    "axes[1,0].set_title('ğŸ“Š Precision-Recall EÄŸrileri', fontweight='bold')\n",
    "axes[1,0].set_xlabel('Recall')\n",
    "axes[1,0].set_ylabel('Precision')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Feature importance (en iyi model iÃ§in)\n",
    "if hasattr(results[best_model_name]['model'], 'feature_importances_'):\n",
    "    feature_names = tfidf.get_feature_names_out()\n",
    "    importances = results[best_model_name]['model'].feature_importances_\n",
    "    \n",
    "    top_indices = np.argsort(importances)[-20:]\n",
    "    top_features = [feature_names[i] for i in top_indices]\n",
    "    top_importances = importances[top_indices]\n",
    "    \n",
    "    axes[1,1].barh(range(len(top_features)), top_importances, color='orange')\n",
    "    axes[1,1].set_yticks(range(len(top_features)))\n",
    "    axes[1,1].set_yticklabels(top_features)\n",
    "    axes[1,1].set_title(f'ğŸŒŸ En Ã–nemli Ã–zellikler ({best_model_name})', fontweight='bold')\n",
    "    axes[1,1].set_xlabel('Ã–nem Skoru')\n",
    "\n",
    "# 6. Model karÅŸÄ±laÅŸtÄ±rma radar chart\n",
    "metrics = ['DoÄŸruluk', 'CV Ortalama']\n",
    "model_metrics = np.array([[results[name]['accuracy'], results[name]['cv_mean']] for name in model_names])\n",
    "\n",
    "# Normalize et\n",
    "model_metrics_norm = (model_metrics - model_metrics.min(axis=0)) / (model_metrics.max(axis=0) - model_metrics.min(axis=0))\n",
    "\n",
    "for i, name in enumerate(model_names):\n",
    "    axes[1,2].plot(metrics, model_metrics_norm[i], 'o-', label=name, color=colors[i % len(colors)])\n",
    "\n",
    "axes[1,2].set_title('ğŸ“¡ Model Performans Radar', fontweight='bold')\n",
    "axes[1,2].legend()\n",
    "axes[1,2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../analysis/gelismis_model_analizi.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nğŸ† En iyi model: {best_model_name}\")\n",
    "print(f\"ğŸ¯ Test doÄŸruluÄŸu: {results[best_model_name]['accuracy']:.4f}\")\n",
    "print(f\"ğŸ”„ CV doÄŸruluÄŸu: {results[best_model_name]['cv_mean']:.4f} (Â±{results[best_model_name]['cv_std']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DetaylÄ± model raporu\n",
    "print(\"ğŸ“‹ DETAYLI MODEL PERFORMANS RAPORU\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name in model_names:\n",
    "    print(f\"\\nğŸ¤– {name}:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Test DoÄŸruluÄŸu: {results[name]['accuracy']:.4f}\")\n",
    "    print(f\"CV DoÄŸruluÄŸu: {results[name]['cv_mean']:.4f} (Â±{results[name]['cv_std']:.4f})\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, results[name]['predictions'], \n",
    "                              target_names=['Sahte', 'GerÃ§ek']))\n",
    "\n",
    "# En iyi modeli kaydet\n",
    "import joblib\n",
    "best_model = results[best_model_name]['model']\n",
    "joblib.dump(best_model, f'../models/en_iyi_model_{best_model_name.lower().replace(\" \", \"_\")}.pkl')\n",
    "joblib.dump(tfidf, '../models/tfidf_vectorizer.pkl')\n",
    "\n",
    "print(f\"\\nğŸ’¾ En iyi model kaydedildi: {best_model_name}\")\n",
    "print(\"ğŸ’¾ TF-IDF vektÃ¶rizer kaydedildi\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
